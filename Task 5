import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import torchvision.transforms.functional as F
from torchvision.datasets import CocoDetection
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection import transform

# Set the device to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Step 1: Load and Preprocess the COCO Dataset

train_dataset = CocoDetection(root='path_to_train_images', 
                               annFile='path_to_train_annotations')

val_dataset = CocoDetection(root='path_to_val_images', 
                             annFile='path_to_val_annotations')

# Define transformations for data augmentation and normalization
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Apply transformation to the dataset
train_dataset = CocoDetection(root='path_to_train_images', 
                               annFile='path_to_train_annotations', 
                               transforms=transform)

val_dataset = CocoDetection(root='path_to_val_images', 
                             annFile='path_to_val_annotations', 
                             transforms=transform)

# Step 2: Define the Pre-trained Faster R-CNN Model and Fine-Tune It

# Load pre-trained Faster R-CNN model
model = fasterrcnn_resnet50_fpn(pretrained=True)

# Modify the classifier to match the number of classes in COCO (91 classes: 80 objects + 1 for background)
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 91)  # COCO has 91 classes

# Move model to device
model.to(device)

# Step 3: Define DataLoader for Training and Validation Datasets

train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))
val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))

# Step 4: Define Optimizer and Scheduler

# Define the optimizer for training
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)

# Define a learning rate scheduler
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

# Step 5: Training the Model

num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, targets in train_dataloader:
        images = [image.to(device) for image in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        
        # Zero the gradients
        optimizer.zero_grad()
        
        # Forward pass
        loss_dict = model(images, targets)
        
        # Backward pass and optimization
        losses = sum(loss for loss in loss_dict.values())
        losses.backward()
        optimizer.step()
        
        running_loss += losses.item()

    # Step the learning rate scheduler
    lr_scheduler.step()

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_dataloader)}')

# Step 6: Save the Model Weights

torch.save(model.state_dict(), 'fasterrcnn_coco.pth')

# Step 7: Evaluating the Model

model.eval()

def evaluate(model, data_loader):
    # Use the model to predict and calculate mAP (mean Average Precision)
    pass

coco_evaluator = evaluate(model, val_dataloader)
print(f"mAP: {coco_evaluator}")

# Step 8: Visualize Predictions with Bounding Boxes

def plot_boxes(image, boxes, labels, scores, threshold=0.5):
    image = image.cpu().numpy().transpose(1, 2, 0)
    plt.imshow(image)
    ax = plt.gca()
    
    for i in range(len(boxes)):
        if scores[i] > threshold:
            box = boxes[i].cpu().numpy()
            label = labels[i].cpu().numpy()
            score = scores[i].cpu().numpy()
            rect = Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],
                             linewidth=2, edgecolor='r', facecolor='none')
            ax.add_patch(rect)
            ax.text(box[0], box[1], f'{label}: {score:.2f}', color='white', fontsize=12)
    plt.show()

# Load a sample image for prediction from validation dataset
image, _ = val_dataset[0]
image = image.unsqueeze(0).to(device)

# Get predictions from the model
with torch.no_grad():
    prediction = model(image)

# Visualize the predicted bounding boxes and labels
boxes = prediction[0]['boxes']
labels = prediction[0]['labels']
scores = prediction[0]['scores']
plot_boxes(image[0], boxes, labels, scores)

# Step 9: Save the Model Weights

torch.save(model.state_dict(), 'fasterrcnn_coco.pth')
